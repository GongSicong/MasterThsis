{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\"\"\" Libraries \"\"\"\n",
    "import os\n",
    "import json\n",
    "import time as tm\n",
    "import pyproj\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import nbimporter\n",
    "from Core import json_numpy_serializer\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "pd.set_option('display.max_rows', None)\n",
    "tqdm.pandas(desc=\"Processing time\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\" Parameters \"\"\"\n",
    "para = {\n",
    "    \"fold_test\": \"test\",\n",
    "    \"fold_data\": \"data\",\n",
    "    \"fold_para\": \"para\",\n",
    "    \"geo_crs\": \"EPSG:4326\",\n",
    "    \"pro_crs\": \"EPSG:4549\",\n",
    "    \"latitude_0\": 22.2,\n",
    "    \"latitude_n\": 22.4,\n",
    "    \"longitude_0\": 113.4,\n",
    "    \"longitude_n\": 113.6,\n",
    "    \"time_0\": \"2021-10-14 00:00:00\",\n",
    "    \"time_n\": \"2021-10-15 00:00:00\",\n",
    "}\n",
    "\n",
    "fold_test = para[\"fold_test\"]\n",
    "fold_para = para[\"fold_para\"]\n",
    "geo_crs = para[\"geo_crs\"]\n",
    "pro_crs = para[\"pro_crs\"]\n",
    "latitude_0, longitude_0, time_0 = para[\"latitude_0\"], para[\"longitude_0\"], para[\"time_0\"]\n",
    "latitude_n, longitude_n, time_n = para[\"latitude_n\"], para[\"longitude_n\"], para[\"time_n\"]\n",
    "\n",
    "# Delete existing para files\n",
    "if os.path.exists(fold_para):\n",
    "    files = os.listdir(fold_para)\n",
    "    for file in files:\n",
    "        os.remove(\"{}/{}\".format(fold_para, file))  # Remove all files\n",
    "else:\n",
    "    os.makedirs(fold_para)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d63824ee21f4b718f8e3df72d4d53a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Data Sampling \"\"\"\n",
    "# Delete existing test file\n",
    "if os.path.exists(\"test.csv\"):\n",
    "    os.remove(\"test.csv\")\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Sample first n taxi\n",
    "df = pd.read_csv(filepath_or_buffer=\"taxi.csv\", sep=\",\", header=None)\n",
    "df.rename(columns={0: \"taxiId\", 1: \"time\", 2: \"latitude\", 3: \"longitude\", 4: \"state\"}, inplace=True)\n",
    "groups = df.groupby(\"taxiId\")\n",
    "for i, (taxiId, group) in tqdm(enumerate(groups)):\n",
    "    path = \"test.csv\"\n",
    "    group.to_csv(path_or_buf=path, index=False, header=not os.path.exists(path), mode=\"a\")\n",
    "    if i >= 1006 - 1:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\"\"\" Re-encoding Functions \"\"\"\n",
    "# Projection Transformer\n",
    "transformer = pyproj.Transformer.from_crs(pyproj.CRS(geo_crs), pyproj.CRS(pro_crs), always_xy=True)\n",
    "\n",
    "\n",
    "# Re-encode the space\n",
    "def reEncode_space(longitude, latitude):\n",
    "    x, y = transformer.transform(longitude, latitude)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Re-encode the time\n",
    "def reEncode_time(time):\n",
    "    t = tm.mktime(tm.strptime(time, \"%Y-%m-%d %H:%M:%S\"))\n",
    "    return t\n",
    "\n",
    "\n",
    "# Re-encode the state\n",
    "def reEncode_state(state):\n",
    "    s = 1 if state == 3 else 0\n",
    "    return s\n",
    "\n",
    "\n",
    "# Re-encode the all\n",
    "def reEncode_combine(longitude, latitude, time, state):\n",
    "    x, y = reEncode_space(longitude, latitude)\n",
    "    t = reEncode_time(time)\n",
    "    s = reEncode_state(state)\n",
    "    return int(x), int(y), int(t), int(s)\n",
    "\n",
    "\n",
    "# Space extent\n",
    "x_0, y_0 = reEncode_space(longitude_0, latitude_0)\n",
    "x_n, y_n = reEncode_space(longitude_n, latitude_n)\n",
    "# Time extent\n",
    "t_0 = reEncode_time(time_0)\n",
    "t_n = reEncode_time(time_n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d351d008537047a796d70a3bf4661bf5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Data Re-encoding and Reorganizing \"\"\"\n",
    "# Delete existing test files\n",
    "if os.path.exists(fold_test):\n",
    "    files = os.listdir(fold_test)\n",
    "    for file in files:\n",
    "        os.remove(\"{}/{}\".format(fold_test, file))  # Remove all files\n",
    "else:\n",
    "    os.makedirs(fold_test)\n",
    "\n",
    "# Re-encode, filter and reorganize the data\n",
    "df = pd.read_csv(filepath_or_buffer=\"test.csv\", sep=\",\", iterator=True, chunksize=50000)\n",
    "for chunk in tqdm(df):\n",
    "    chunk[[\"x\", \"y\", \"t\", \"s\"]] = chunk.apply(lambda x: reEncode_combine(x[\"longitude\"], x[\"latitude\"], x[\"time\"], x[\"state\"]), axis=1, result_type='expand')\n",
    "    chunk = chunk[(chunk['x'] >= x_0) & (chunk['x'] <= x_n) & (chunk['y'] >= y_0) & (chunk['y'] <= y_n)]\n",
    "    chunk = chunk[(chunk['t'] >= t_0) & (chunk['t'] <= t_n)]\n",
    "    chunk_groups = chunk.groupby(\"taxiId\")\n",
    "    for taxiId, chunk_group in chunk_groups:\n",
    "        path = \"{}/{}.csv\".format(fold_test, taxiId)\n",
    "        chunk_group.to_csv(path_or_buf=path, index=False, header=not os.path.exists(path), mode=\"a\", columns=['x', 'y', 't', 's'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "801c836978aa4922964cf92fc6d144b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Data Cleaning \"\"\"\n",
    "\n",
    "# Drop na and duplicates\n",
    "files = os.listdir(fold_test)\n",
    "for file in tqdm(files):\n",
    "    df = pd.read_csv(filepath_or_buffer=\"{}/{}\".format(fold_test, file), sep=\",\")\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    if len(df) <= 1:\n",
    "        os.remove(\"{}/{}\".format(fold_test, file))\n",
    "    else:\n",
    "        df.to_csv(path_or_buf=\"{}/{}\".format(fold_test, file), index=False, mode='w')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db8830f17cde41b2ba3de689aff5e240"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Min and Max Calculating \"\"\"\n",
    "\n",
    "# Initialize min and max\n",
    "t_min, x_min, y_min = float(\"inf\"), float(\"inf\"), float(\"inf\")\n",
    "x_max, y_max, t_max = float(\"-inf\"), float(\"-inf\"), float(\"-inf\")\n",
    "\n",
    "# Calculate min and max\n",
    "files = os.listdir(fold_test)\n",
    "for file in tqdm(files):\n",
    "    df = pd.read_csv(filepath_or_buffer=\"{}/{}\".format(fold_test, file), sep=\",\")\n",
    "    # Update minimums\n",
    "    x_min_tmp, y_min_tmp, t_min_tmp = df[\"x\"].min(), df[\"y\"].min(), df[\"t\"].min()\n",
    "    x_min = x_min_tmp if x_min_tmp <= x_min else x_min\n",
    "    y_min = y_min_tmp if y_min_tmp <= y_min else y_min\n",
    "    t_min = t_min_tmp if t_min_tmp <= t_min else t_min\n",
    "    # Update maximums\n",
    "    x_max_tmp, y_max_tmp, t_max_tmp = df[\"x\"].max(), df[\"y\"].max(), df[\"t\"].max()\n",
    "    x_max = x_max_tmp if x_max_tmp >= x_max else x_max\n",
    "    y_max = y_max_tmp if y_max_tmp >= y_max else y_max\n",
    "    t_max = t_max_tmp if t_max_tmp >= t_max else t_max\n",
    "\n",
    "para[\"x_min\"], para[\"y_min\"], para[\"t_min\"] = x_min, y_min, t_min\n",
    "para[\"x_max\"], para[\"y_max\"], para[\"t_max\"] = x_max, y_max, t_max"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\"\"\" Parameters \"\"\"\n",
    "with open(\"para.json\", \"w\") as json_file:\n",
    "    json.dump(para, json_file, default=json_numpy_serializer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}